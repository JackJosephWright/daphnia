Write down any new tasks to completegit

TODO IDEAS:


check if y#wcentroid is the same as Y etc...









CURRENT MAIN TODO:



2. add new zip functions to src
    -modify zip.py for the final src file
    -install pytest
    -tutorial on pytest
    -write 2 normal case tests
    -write 2 edge case tests


3. write function to standardize plotting of the fish df. 
    -do a tutorial on matplotlib 
    -do a quick tutorial on pandas dataframes
    -plot graph 


GETTING CLEAN DATA:

    Ibrahim


    GOAL: get a reasonable estimate of the daphnia top speed for our data cleaning function

   
    2. cut the data into separate tables (if there is missing data, start a new table)

    3. look at the distribution of lengths (how long each segment is, you could do the last row's t - the first rows t)
        throw out the tables that are too short
    4. calculate the velocity (d/t) between every point in the good data. plot this as a distribution

    5. come up with a reasonable estimate for the daphnias TOP SPEED


CHECK LOGIC OF TRexDataCleaner:

it might be better to return 1 df with <inf> or some NA value instead of two sepearate dataframe for imputation purposes



IMPUTER_CLASS:

name: DaphniaImputer

this class will handle the imputation of the data from clean dataframes of the proper order (from TRexDataCleaner)

1.

create folder src/data_manipulation/imputers

add "imputer1.py" that replaces all missing data as 9999 (or some constant)

2.

as part of the initialization of the class, have it iterate through the files in src/data_manipulation/imputers and assign the functions to a dictionary:

example:

imputer_dict['imputer1.py'] = <function in imputer1.py>

so it can be called self.imputer_dict['imputer1.py'](data) and it will impute the data

write a .impute method where the arguments are the data and the name of the file of the imputer you want to use (it will be loaded in when the class is initialized)

EX:

f = DaphniaImputer()
f.impute(data, 'imputer1.py')
return
[imputed data]

LARGER GOALS:



outline missing data:

    goal:

    fill in missing data in in one of the files inside the .npz with some strategy for data imputation

    process:

    locate the .npz file: 

    unzip the file:

    combine vectors in unzipped npz into a table 

    *decide how to define a missing segment* 


    want:

    argument in function that accepts an imputation strategy


